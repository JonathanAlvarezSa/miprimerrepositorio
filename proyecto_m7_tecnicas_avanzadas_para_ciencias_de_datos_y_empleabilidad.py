# -*- coding: utf-8 -*-
"""Proyecto_M7_Tecnicas_Avanzadas_para_ciencias_de_datos_y_empleabilidad.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PbUTBq9Jh5nek5IHT5ErV0YhGCxNI4lQ
"""



"""## **Bootcamp: Ciencia de Datos e Inteligencia Artificial**
## **Proyecto del Módulo 7: Técnicas avanzadas para ciencia de datos y empleabilidad**

Hola, ya es el último proyecto, has avanzado y aprendido mucho hasta acá. ¡Muchas felicidades!

Es hora de poner en práctica todo lo que hemos aprendido a lo largo de nuestra travesía.

Lee el proyecto y revisa con cuidado cada una de las instrucciones. Procura plasmar todo tu potencial para que lo concluyas de manera sobresaliente.

¡Éxito!

# Objetivos
- Aplicar con éxito todos los conocimientos que has adquirido a lo largo del Bootcamp.
- Consolidar las técnicas de limpieza, entrenamiento, graficación y ajuste a modelos de *Machine Learning*.
- Generar una API que brinde predicciones como resultado a partir de datos enviados.

# Proyecto

1. Selecciona uno de los siguientes *datasets*:
  - *Reviews* de aplicaciones de la Google Play Store: https://www.kaggle.com/datasets/lava18/google-play-store-apps
  - Estadísticas demográficas de los ganadores del premio Oscar de la Academia: https://www.kaggle.com/datasets/fmejia21/demographics-of-academy-awards-oscars-winners
  - Aspiraciones profesionales de la generación Z: https://www.kaggle.com/datasets/kulturehire/understanding-career-aspirations-of-genz
  -Radiografias de neumonia:
  https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia/data

Cada uno representa un *dataset*, un problema y una forma diferente de abordarlo. Tu tarea es identificar las técnicas y modelos que podrías usar para tu proyecto.

2. Debes hacer un análisis exploratorio y limpieza de los datos. Usa las ténicas que creas convenientes.

3. Entrena el modelo de *Machine Learning*, procesamiento de lenguaje natural o red neuronal que creas adecuado.

4. Genera por lo menos dos gráficas y dos métricas de rendimiento; explica las puntuaciones de rendimiento que amerite tu problema. Todas las gráficas de rendimiento que realices deben tener leyendas, colores y títulos personalizados por ti.

  - Además, antes de subir el modelo a "producción", deberás realizar un proceso de ensambles (*ensemblings*) y de ajuste de hiperparámetros o *tuning* para intentar mejorar la precisión y disminuir la varianza de tu modelo.

5. Construye una API REST en la que cualquier usuario pueda mandar datos y que esta misma devuelva la predicción del modelo que has hecho. La API debe estar en la nube, ya sea en un servicio como Netlify o Ngrok, para que pueda ser consultada desde internet.

6. Genera una presentación del problema y del modelo de solución que planteas. Muestra gráficas, datos de rendimiento y explicaciones. Esta presentación debe estar enfocada a personas que no sepan mucho de ciencia de datos e inteligencia artificial.

7. **Solamente se recibirán trabajos subidos a tu cuenta de GitHub con un README.md apropiado que explique tu proyecto**.

## Criterios de evaluación

| Actividad | Porcentaje | Observaciones | Punto parcial
| -- | -- | -- | -- |
| Actividad 1. Limpieza y EDA | 20 | Realiza todas las tareas necesarias para hacer el EDA y la limpieza correcta, dependiendo de la problemática. Debes hacer como mínimo el análisis de completitud, escalamiento (si aplica) y tokenización (si aplica). | Realizaste solo algunas tareas de exploración y limpieza y el modelo se muestra aún con oportunidad de completitud, escalamiento y/o mejora. |
| Actividad 2. Entrenamiento del modelo | 20 | Elige el modelo y algoritmo adecuados para tu problema, entrénalo con los datos ya limpios y genera algunas predicciones de prueba. | No has realizado predicciones de prueba para tu modelo de ML y/o tu modelo muestra una precisión menor al 60 %. |
| Actividad 3. Graficación y métricas | 20 | Genera por lo menos dos gráficas y dos muestras de métricas que permitan visualizar el rendimiento y precisión del modelo que construiste. Además, realizaste los procesos de *tuning* y ensambles adecuados para tu problema. | Las gráficas no tienen leyendas y colores customizados, solo muestras una gráfica o no realizaste el *tuning* de hiperparámetros.
| Actividad 4. API REST | 20 | Generaste con éxito un *link* público en el que, por método POST, se puede mandar información y la API REST devuelve una predicción junto con el porcentaje de confianza de esta misma. | N/A
| Actividad 5. Presentación | 20 | Genera una presentación en la que establezcas como mínimo: el problema, proceso de solución, metodologías usadas, gráficas de rendimiento, demostración del modelo y aprendizajes obtenidos. Debes redactarla con términos que pueda entender cualquier persona, no solo científicos de datos. | La presentación no expone con claridad o en términos coloquiales el proceso de creación del modelo, sus ventajas y muestras de rendimiento.

**Mucho éxito en tu camino como Data Scientist.**
"""

#Import Os and Basis Libraries
import cv2
import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
#Matplot Images
import matplotlib.image as mpimg
# Tensflor and Keras Layer and Model and Optimize and Loss
import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization

from tensorflow.keras.losses import BinaryCrossentropy
#Kernel Intilizer
from sklearn.preprocessing import LabelEncoder
# import tensorflow_hub as hub
from tensorflow.keras.optimizers import Adam , Adamax
#PreTrained Model
from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3, MobileNet
#Early Stopping
from tensorflow.keras.callbacks import EarlyStopping
# Warnings Remove
import warnings
warnings.filterwarnings("ignore")

#Para importar una imagen a Python, necesitas utilizar la biblioteca Pillow.
!pip install Pillow

!pip install --upgrade Pillow

#Existen dos maneras de importar una imagen a Python con Pillow:

# 1. Usando Image.open():
# Python
from PIL import Image

# imagen = Image.open("ruta/a/imagen.jpg")

# # Mostrar la imagen
# imagen.show()

# from PIL import Image

# 2.imagen = Image.load("ruta/a/imagen.jpg")

# # Mostrar la imagen
# imagen.show()

from google.colab import drive
drive.mount('/content/drive')

#image_path = "/content/drive/MyDrive/Proyecto 7 UCAMP 2024/radiografiasdataset/chest_xray/train/NORMAL"

# carpeta_imagenes = "/content/drive/MyDrive/Proyecto 7 UCAMP 2024/radiografiasdataset/chest_xray/train/NORMAL"

# for archivo in os.listdir(carpeta_imagenes):
#     ruta_imagen = os.path.join(carpeta_imagenes, archivo)
#     imagen = Image.open(ruta_imagen)
#     imagen.show()

# #Directory contiene la carpeta de "entrenamiento/Train"
directory = "/content/drive/MyDrive/Proyecto 7 UCAMP 2024/radiografiasdataset/chest_xray/train"

filepath =[]
label = []

carpetas = os.listdir(directory)

for carpeta in carpetas:
    c_path = os.path.join(directory , carpeta)

    imgs = os.listdir(c_path)

    for img in imgs:

        img_path = os.path.join(c_path , img)
        filepath.append(img_path)
        label.append(carpeta)

#Concatenar el camino del archivo/filepath del dataset con las etiquetas/labels
file_path_series = pd.Series(filepath , name= 'filepath')
Label_path_series = pd.Series(label , name = 'label')
df_train = pd.concat([file_path_series ,Label_path_series ] , axis = 1)

# directory la variable que contiene la ruta de la carpeta que contiene las imágenes.

#filpepath [] una lists que almacenara las rutas de las imagenes

#label [] una lista vacia para almacenar el nombre de las imagenes

#El ciclo for carpeta in carpetas:itera a través de cada subcarpeta (carpeta ) obtenido en el paso anterior.

# os.listdir()devuelve una lista con los nombres de los archivos en la carpeta (directory)
# obtener una lista de todas las carpetas (subdirectorios) dentro del directorio principal ( directory).
#Estas carpetas probablemente representan diferentes categorías de radiografías (por ejemplo, "NORMAL", "NEUMONIA").

#c_path Esta línea una ruta del directorio principal ( directory) con el nombre de la subcarpeta actual ( carpeta) para crear la ruta completa del subdirectorio.

#img_path = os.path.join(c_path, img): Esta línea construye la ruta completa de la imagen actual ( img) uniéndola a la ruta del subdirectorio ( c_path).

# os.path.join()se utiliza para concatenar la ruta de la carpeta con el nombre  del archivo para obtener la ruta completa de la imagen.

# from google.colab import files
# uploaded= files.upload()

df_train.info()
#Verificamos si tenemos datos nulos

df_train

df_train['label'].value_counts()

# indices_a_eliminar = list(range(2681,5215))

# df_train = df_train.drop(df_train.index[indices_a_eliminar])

# df_train["label"].value_counts()
# #DATASET EQUILIBRADO

#Se repetira el codigo para la carpeta de test
directory_test= "/content/drive/MyDrive/Proyecto 7 UCAMP 2024/radiografiasdataset/chest_xray/test"

filepath_test=[]
label_test=[]

carpetas_test=os.listdir(directory_test)

for carpeta in carpetas_test:
    c_path_test=os.path.join(directory_test,carpeta)

    imgs_test=os.listdir(c_path_test)

    for img in imgs_test:
      img_path_test=os.path.join(c_path_test,img)
      filepath_test.append(img_path_test)
      label_test.append(carpeta)

#Concatenar el camino del archivo/path con las etiquetas/labels
file_path_series_test=pd.Series(filepath_test,name="filepath")
label_path_series_test=pd.Series(label_test,name="label")
df_test=pd.concat([file_path_series_test,label_path_series_test],axis=1)

df_test

df_test['label'].value_counts()

# indices_a_eliminar_test = list(range(0,166))

# df_test = df_test.drop(df_test.index[indices_a_eliminar_test])

# df_test["label"].value_counts()

df_test.head(10)

df_test.tail(10)

#Shape
print(f"La forma del dataset de entramiento es: {df_train.shape}")
print(f"La forma del dataset de testeo es: {df_test.shape}")

directory_train ="/content/drive/MyDrive/Proyecto 7 UCAMP 2024/radiografiasdataset/chest_xray/train"
directory_test="/content/drive/MyDrive/Proyecto 7 UCAMP 2024/radiografiasdataset/chest_xray/test"

img_size=(256,256)

print('imagenes de entrenamiento/train:')
#Elaborar el dataset de entrenamiento/train
dataset_train=tf.keras.utils.image_dataset_from_directory(
    directory_train,
    batch_size=32,
    image_size=img_size,
    validation_split=0.1,
    seed=123,
    subset='training')

print('imagenes de validacion/val:')
dataset_val=tf.keras.utils.image_dataset_from_directory(
     directory_train,
     batch_size=32,
     image_size=img_size,
     validation_split=0.1,
     seed=123,
     subset='validation')

print('imagenes de testeo/test:')
dataset_test=tf.keras.utils.image_dataset_from_directory(
    directory_test,
    batch_size=32,
    image_size=img_size,
    seed=123)

"""## **DEFINIR CLASES**"""

train_labels=dataset_train.class_names

test_labels=dataset_test.class_names

val_labels=dataset_val.class_names

#Definir las clases NORMAL[SANO], y PEUMONIA[ENFERMO]

class_labels=["NORMAL","PNEUMONIA"]

#Instancia LabelEncoder
label_e=LabelEncoder()

#Rellena label_e con las clases
label_e.fit(class_labels)

#Transformar las etiquetas/labels

train_labels_e=label_e.transform(train_labels)
test_labels_e=label_e.transform(test_labels)
val_labels_e=label_e.transform(val_labels)

for image_batch,label_batch in dataset_train:
  print("Shape of X_train",image_batch.shape)
  print("Shape of y_train",label_batch.shape)
  break
  #2 min

"""# **Hay que normalizar los valores para que puedan estar a escala.**




"""

# Se dividen los datos entre 255 para normalizarlos porque los valores únicamente van entre 0 y 255 que son los píxeles
dataset_train=dataset_train.map(lambda x,y: (x/255,y))
dataset_test=dataset_test.map(lambda x,y: (x/255,y))
dataset_val=dataset_val.map(lambda x,y: (x/255,y))

"""## **VISUALIZACION DF_TRAIN**"""

registro=df_train['label'].value_counts()

fig, axs= plt.subplots(1, 2, figsize=(12, 5), facecolor="white")

sns.barplot(x=registro.index, y=registro.values, ax=axs[0], palette="husl")
axs[0].set_title("Registro de categorías")
axs[0].set_xlabel("Categoría")
axs[0].set_ylabel("Frecuencia")

# Agrega una línea punteada horizontal en el valor 1500
axs[0].axhline(y=1500, linestyle="dashed", color="gray", linewidth=1)

# Porcentajes
sns.barplot(x=registro.index, y=registro.values / registro.sum() * 100, ax=axs[1], palette="pastel")
axs[1].set_title("Porcentaje de categorías")
axs[1].set_xlabel("Categoría")
axs[1].set_ylabel("Porcentaje")

# Agrega una línea punteada horizontal en el valor 25%
axs[1].axhline(y=25, linestyle="dashed", color="gray", linewidth=1)

plt.show()

"""## **VISUALIZACION DF_TEST**"""

registro_test=df_test['label'].value_counts()

fig, axs= plt.subplots(1, 2, figsize=(16, 8), facecolor="white")

sns.barplot(x=registro_test.index, y=registro_test.values, ax=axs[0], palette="husl")
axs[0].set_title("Registro de categorías")
axs[0].set_xlabel("Categoría")
axs[0].set_ylabel("Frecuencia")

# Agrega una línea punteada horizontal en el valor 1500
axs[0].axhline(y=200, linestyle="dashed", color="gray", linewidth=1)

# Porcentajes
sns.barplot(x=registro_test.index, y=registro_test.values / registro_test.sum() * 100, ax=axs[1], palette="pastel")
axs[1].set_title("Porcentaje de categorías")
axs[1].set_xlabel("Categoría")
axs[1].set_ylabel("Porcentaje")

# Agrega una línea punteada horizontal en el valor 40%
axs[1].axhline(y=40, linestyle="dashed", color="gray", linewidth=1)

plt.show()

def visualiza_imagenes(path, num_imagenes=7):

  imagenes_nombre=os.listdir(path)

  num_imagenes=min(num_imagenes,len(imagenes_nombre))

  fig, axs=plt.subplots(1,num_imagenes,figsize=(18,5),facecolor="white")

  for i,imagenes_nombre in enumerate(imagenes_nombre[:num_imagenes]):

    image_path=os.path.join(path,imagenes_nombre)
    imagen=mpimg.imread(image_path)

    #Visualizar la imagen
    axs[i].imshow(imagen, cmap="gray") #Visualizar en gris
    axs[i].set_title(imagenes_nombre)
    axs[i].axis("off")#Sin ejes

#plt.tight_layout()
plt.show()

path_visualizar="/content/drive/MyDrive/Proyecto 7 UCAMP 2024/radiografiasdataset/chest_xray/train/NORMAL"
visualiza_imagenes(path_visualizar, num_imagenes=7)

path_visualizar_p="/content/drive/MyDrive/Proyecto 7 UCAMP 2024/radiografiasdataset/chest_xray/train/PNEUMONIA"
visualiza_imagenes(path_visualizar_p, num_imagenes=8)

"""## **MODELO**"""

# Tipos de modelos de redes neuronales:
# 1. Redes neuronales perceptrón:

# Son las redes neuronales más simples.
# Se utilizan para problemas de clasificación binaria.
# Consisten en una capa de entrada, una capa oculta y una capa de salida.

# 2. Redes neuronales multicapa:
# Son más complejas que los perceptrones.
# Se pueden usar para problemas de clasificación y regresión.
# Contiene múltiples capas ocultas entre la capa de entrada y la capa de salida.

# 3. Redes neuronales convolucionales:
# Se utilizan para procesar datos espaciales, como imágenes.
# Contienen capas convolucionales que extraen características de los datos.
# Se utilizan para tareas como clasificación de imágenes, detección de objetos y segmentación de imágenes.

# 4. Redes neuronales recurrentes:
# Se utilizan para procesar datos secuenciales, como texto o series temporales.
# Contienen capas recurrentes que permiten que la red "recuerde" información de entradas anteriores.
# Se utilizan para tareas como traducción automática, reconocimiento de voz y generación de texto.

# 5. Redes neuronales profundas:
# Son redes neuronales con muchas capas.
# Se pueden usar para una gran variedad de tareas, como reconocimiento de imágenes, procesamiento del lenguaje natural y traducción automática.
# Requieren grandes cantidades de datos y recursos computacionales para entrenar.
# Otras redes neuronales:

# Redes neuronales autoencoder: para aprender representaciones eficientes de datos.
# Redes neuronales generativas: para generar datos nuevos, como imágenes o texto.
# Redes neuronales de refuerzo: para aprender a tomar decisiones en un entorno.

"""# ** Redes neuronales convolucionales:**
 Se utilizan para procesar datos espaciales, como imágenes.
 Contienen capas convolucionales que extraen características de los datos.
 Se utilizan para tareas como clasificación de imágenes, detección de objetos y segmentación de imágenes.
"""



"""
Técnicas de Aprendizaje Automático
El Machine Learning (Aprendizaje Automático) es un campo de la Inteligencia Artificial que se enfoca en entrenar algoritmos para aprender de los datos y realizar predicciones o tomar decisiones de forma autónoma. Existen diversas técnicas de Machine Learning que se pueden agrupar en tres categorías principales:

 Aprendizaje Supervisado:

En este tipo de aprendizaje, el algoritmo se entrena con un conjunto de datos etiquetados. Los datos contienen entradas (características) y salidas deseadas (objetivos). El objetivo es aprender la relación entre las entradas y las salidas para poder predecir las salidas para nuevos datos no vistos."""

from keras.applications import Xception

"""Presentamos una interpretación de los módulos Inception en redes neuronales convolucionales como un paso intermedio entre la convolución regular y la operación de convolución separable en profundidad (una convolución en profundidad seguida de una convolución puntual). Desde este punto de vista, una convolución separable en profundidad puede entenderse como un módulo Inception con un número máximo de torres. Esta observación nos lleva a proponer una nueva arquitectura de red neuronal convolucional profunda inspirada en Inception, donde los módulos de Inception han sido reemplazados por convoluciones separables en profundidad.

include_top: whether to include the 3 fully-connected layers at the top of the network.

weights: one of None (random initialization), "imagenet" (pre-training on ImageNet), or the path to the weights file to be loaded.

input_tensor: optional Keras tensor (i.e. output of layers.Input()) to use as image input for the model.

input_shape: optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (299, 299, 3). It should have exactly 3 inputs channels, and width and height should be no smaller than 71. E.g. (150, 150, 3) would be one valid value.

pooling: Optional pooling mode for feature extraction when include_top is False.

None means that the output of the model will be the 4D tensor output of the last convolutional block.

avg means that global average pooling will be applied to the output of the last convolutional block, and thus the output of the model will be a 2D tensor.

max means that global max pooling will be applied.
"""

# include_top: whether to include the 3 fully-connected layers at the top of the network.

# weights: one of None (random initialization), "imagenet" (pre-training on ImageNet), or the path to the weights file to be loaded.

# input_tensor: optional Keras tensor (i.e. output of layers.Input()) to use as image input for the model.

# input_shape: optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (299, 299, 3).
# It should have exactly 3 inputs channels, and width and height should be no smaller than 71. E.g. (150, 150, 3) would be one valid value.

# pooling: Optional pooling mode for feature extraction when include_top is False.

# None means that the output of the model will be the 4D tensor output of the last convolutional block.

# avg means that global average pooling will be applied to the output of the last convolutional block, and thus the output of the model will be a 2D tensor.

# max means that global max pooling will be applied.

#del model

modelo_base= Xception(weights='imagenet', include_top=False, pooling='avg', input_shape=(256,256,3))

modelo_base.trainable=False

"""Cuando se establece trainable=False, los pesos de las capas del modelo base no se actualizarán durante el entrenamiento.

Esto es útil cuando se utiliza la técnica de transferencia de aprendizaje, donde se desea aprovechar el conocimiento preentrenado de un modelo como Xception.

Al congelar las capas del modelo base, se evita que se sobreajusten a su conjunto de datos específico, lo que puede mejorar el rendimiento general.
"""

#Armamos el modelo convulucional

model=Sequential()
model.add(modelo_base)
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(Dense(240,activation='relu'))
model.add(Dropout(0.25))

model.add(Dense(40,activation='relu'))
model.add(Dense(1,activation='sigmoid'))

"""
Batch Normalization (Normalización por Lotes) es una técnica de normalización utilizada en redes neuronales profundas para acelerar el entrenamiento y mejorar la estabilidad."""

from tensorflow.keras.optimizers import Adamax

# Compilación del modelo y su resumen para ver lo que se encuentran en las capas para poder trabajar
# model.compile(loss='categorical_crossentropy', optimizer=Adamax(learning_rate=0.001), metrics=['accuracy'])
# model.summary()

# Compilación del modelo y su resumen para ver lo que se encuentran en las capas para poder trabajar
model.compile(loss='binary_crossentropy', optimizer=Adamax(learning_rate=0.0001), metrics=['accuracy'])
model.summary()

early_stopping= EarlyStopping(monitor='val_loss',patience=7, restore_best_weights=True)

history=model.fit_generator(dataset_train, epochs=20, validation_data=dataset_val, callbacks=early_stopping,) #9min

validation_loss,validation_accuracy=model.evaluate(dataset_val)

print("validation_loss:",validation_loss)
print("validation_accuracy:",validation_accuracy)

mejor_epoch=history.history["val_accuracy"].index(max(history.history["val_accuracy"]))+1
print(f'El mejor epoch es el numero:{mejor_epoch}')

#  # Obtener las métricas
#  history = model.history
#  accuracy = history['accuracy']
#  val_accuracy = history['val_accuracy']
#  loss= history['loss']
#  val_loss=history['val_loss']

# fig,axs=plt.subplots(1,2,figsize=(15,5))

#  axs[0].plot(accuracy, label='Precision de entrenamiento', color="yellow")
#  axs[0].plot(val_accuracy, label='Precision de validacion', color="blue")
#  axs[0].scatter(mejor_epoch, max(val_accuracy),color="red", linestyle='dashed', label=f'mejor epoch:{mejor_epoch}')
#  axs[0].set_xlabel("Epochs")
#  axs[0].set_ylabel("Accuracy/Precision")
#  axs[0].set_title("Entrenamiento y validacion Precision/Accuracy")
#  axs[0].legend()

#  axs[1].plot(loss, label='Perdida de entrenamiento', color="yellow")
#  axs[1].plot(val_loss, label="Perdida de validacion", color="blue")
#  axs[1].scatter(mejor_epoch, min(val_loss),color="red", linestyle='dashed' ,label=f'mejor epoch:{mejor_epoch}')
#  axs[1].set_xlabel("Epochs")
#  axs[1].set_ylabel("Loss/perdida")
#  axs[1].set_title("Entrenamiento y validacion perdida/loss")
#  axs[1].legend()

#  plt.show()

print(history.history.keys())

# fig, axs = plt.subplots(1, 2, figsize=(16, 5))


# axs[0].plot(history.history['accuracy'], label='Training Accuracy', color='blue')
# axs[0].plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')
# axs[0].scatter(mejor_epoch - 1, history.history['val_accuracy'][mejor_epoch - 1], color='green', label=f'Best Epoch: {mejor_epoch}')
# axs[0].set_xlabel('Epoch')
# axs[0].set_ylabel('Accuracy')
# axs[0].set_title('Training and Validation Accuracy')
# axs[0].legend()


# axs[1].plot(history.history['loss'], label='Training Loss', color='blue')
# axs[1].plot(history.history['val_loss'], label='Validation Loss', color='red')
# axs[1].scatter(mejor_epoch - 1, history.history['val_loss'][mejor_epoch - 1], color='green',label=f'Best Epoch: {mejor_epoch}')
# axs[1].set_xlabel('Epoch')
# axs[1].set_ylabel('Loss')
# axs[1].set_title('Training and Validation Loss')
# axs[1].legend()


# plt.show()

"""## **PREDICCION DEL MODELO**"""

print('imagenes de testeo/test:')
dataset_test=tf.keras.utils.image_dataset_from_directory(
    directory_test,
    batch_size=32,
    image_size=img_size,
    seed=123)

model

def obtener_imagenes_con_predicciones(model, dataset, class_labels, num_images=25, num_images_per_row=5):
    predictions = model.predict(dataset)
    plt.figure(figsize=(16, 9))

    for i, (images, labels) in enumerate(dataset.take(num_images)):
        images = images.numpy()
        for j in range(len(images)):
            if i * num_images_per_row + j < num_images:
                predicted_class = class_labels[np.argmax(predictions[i * num_images_per_row + j])]
                true_class = class_labels[labels[j]]  # Assuming labels are already indices

                plt.subplot(num_images // num_images_per_row + 1, num_images_per_row, i * num_images_per_row + j + 1)
                plt.imshow(images[j].astype('uint8'))
                plt.title(f'Verdadero: {true_class}\nPredicción: {predicted_class}', color='blue')
                plt.axis('off')

    plt.show()  # Show the plot after all subplots are created

# Call the function with appropriate arguments
print('Testing Images:')
obtener_imagenes_con_predicciones(model, dataset_test, class_labels, num_images=25)

directory_test= "/content/drive/MyDrive/Proyecto 7 UCAMP 2024/radiografiasdataset/chest_xray/test/PNEUMONIA"

#Seleccionar 7 imagenes del directorio
image_files = os.listdir(directory_test)[:7]

#Crear la imagen del archivo del directorio
fig, axs = plt.subplots(1, len(image_files), figsize=(15, 5))

#Cargar y preprocesar cada imagen y hacer la prediccion y mostrarla
for i, image_file in enumerate(image_files):
    img_path = os.path.join(directory_test, image_file)

    img = cv2.imread(img_path)

    img = cv2.resize(img, (256, 256))
#Normalizar valores
    img_array = img.astype(np.float32) / 255.0


    img_array = np.expand_dims(img_array, axis=0)

#Hacer predicciones
    predictiones_2 = model.predict(img_array)
    actual_prediction = (predictiones_2 > 0.5).astype(int)

 #Mostar la imagen con su etiqueta de prediccion
    axs[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    axs[i].axis('off')
    if actual_prediction[0][0] == 0:
        predicted_label = 'Normal'
    else:
        predicted_label = 'PNEUMONIA'
    axs[i].set_title(f'Predicted: {predicted_label}')

# Adjust layout
plt.tight_layout()
plt.show()



# Comprobamos la completitud de nuestro conjunto de datos.
# completitud = pd.DataFrame(df.isnull().sum())
# completitud.reset_index(inplace = True)
# completitud = completitud.rename(columns = {"index":"columna",0:"total"})
# completitud["completitud"] = (1 - completitud["total"] / df.shape[0]) * 100
# completitud = completitud.sort_values(by = "completitud", ascending = False)
# completitud.reset_index(drop = True, inplace = True)
# completitud



#En este punto es importante identificar las variables cuyo porcentaje de completitud es** MENOR** a 80%.
#No es recomendable realizar imputación de valores para estas columnas, pues afectan de manera significativa
#la distribción de datos, además (al carecer mucha información) no son útiles para el modelo

#Se realiza una funcion para en listar las columnas con completitud por DEBAJO del 80%
#null_columnas = list(completitud[completitud["completitud"]<80]["columna"].values)
#null_columnas

#Ahora, borra esas columnas que están en `null_columnas` con la función `drop`.

#Observa bien cómo después del nombre del conjunto de datos (llamado `df`) se coloca `.drop(columns= lista_de_columnas_a_borrar`).

#df = df.drop(columns = null_columnas)
#Las columnas con completitud por debajo del 80% fueron eliminadas